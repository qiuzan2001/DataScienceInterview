### “白名单会越长、Prompt 会撑爆”——如何在 **15 k** 条英文摘要场景里避免这个问题

> 核心原则：**白名单只对 LLM “提示方向”**，不必也不应把 **全部已出现的标签** 永久塞进 Prompt。把它做成 **“候选列表的动态采样 / 检索”**，让长度始终受控，而标签收敛能力依旧存在。

---

## 1 为什么白名单需要动态裁剪

| 若把**全部**历史标签都塞进 Prompt                                                   | 可控做法：**检索＋截断**                                                              |
| ------------------------------------------------------------------------ | --------------------------------------------------------------------------- |
| - 15 k 摘要后即使收敛到 100 leaf 标签，<br>再加别名、派生写法也可能几百项；<br>一次调用就上 1 000+ tokens | - 每次调用只给 **当前摘要最相关** 或 **业务最高频** 的 ≈ 20–50 个候选；<br>Prompt 长度始终 < 300 tokens |
| - 价格、延迟、上下文错乱都上升                                                         | - 成本恒定，模型聚焦“最可能重用”的词汇                                                       |

---

## 2 两种“动态白名单”策略

### 2.1 **相似度检索式（推荐）**

1. **维护一个向量索引**

   * 对当前累计的 *canonical* 标签文本做嵌入；
   * FAISS / sentence-transformers in-memory，都在本地完成。

2. **对每条摘要先做一次快速向量查询**

   * 找到与该摘要语义最近的 **Top-K（如 30）** 标签；
   * 只把这 K 个放进 Prompt 的 “Existing tags: \[…]”。

3. **Prompt 示意**

   ```
   Existing tags (semantic nearest): [refund_request, overcharge, delivery_delay, ...]
   ```

**优点**

* 白名单随摘要内容自动“精简”；
* 即使最终标签池有 500 项，K=30 仍把 Prompt 控制在 ≈ 150 tokens。

---

### 2.2 **高频采样式（简单可行）**

1. 运行一段时间后统计标签出现频次；
2. 将 **Top-N 高频（如 50）** 写进 Prompt；
3. 每周或每天刷新一次这 50 条即可。

**适用**

* 业务主题比较固定，Top-N 标签覆盖率高；
* 不需要实时检索逻辑就能生效。

---

## 3 配合 Few-shot 样例而不是长白名单

即使 K 取得很小，你仍然可以让 LLM 高概率重用标签，方法是在 Prompt 里放 **3-5 行示例对**：

```
Example:
Text: "I want to track my package."
→ {"id":0,"label":"delivery_tracking"}

Text: "Please cancel my subscription and refund me."
→ {"id":0,"label":"subscription_cancel;refund_request"}
```

* 样例示范 **格式、粒度、拼写**；
* 本身就能把模型输出收敛在类似词汇附近；
* 远比一长串白名单更节省 token。

---

## 4 把“全量标签表”移到 **程序** 而非 Prompt

* 解析完模型输出后，**在代码侧** 做规范化、同义折叠、拼写映射；
* 即使模型偶尔新造一个近义词（`refund_application`），程序可用模糊或语义阈值映射回 `refund_request`;
* 这样 **Prompt 长度 ≤ 定值**，而整个系统仍然保持“标签不外扩”。

---

## 5 实测 token 预算

| 组成                                  | token 估算 | 说明            |
| ----------------------------------- | -------- | ------------- |
| 固定规则 + Few-shot                     | ≈ 100    | 长度基本不变        |
| Dynamic whitelist (30 tags × 2 tok) | ≈ 60     | ¹             |
| 摘要文本                                | ≤ 30     | 10-25 words   |
| JSON 响应                             | ≤ 10     | 1-3 tag words |

¹ 一个英文单词平均 0.7-1 token；加括号、逗号后约 2 tok/label。

**总计 ≈ 200 tok**——远低于 4-k 上限，无论单条还是批处理都游刃有余。

---

## 6 总结：确保“白名单助力，不成为负担”

1. **只喂给模型“它当前最可能用到的几十条”**，而非全表。
2. **向量检索 + 高频筛选** 都能做到这一点，成本和实现难度都很低。
3. 代码层面继续做同义折叠，最终让标签池收敛到你期望的 60-100 叶标签。

这样，无论处理第 1 条还是第 15 000 条摘要，Prompt 都保持短小稳定，标签却能持续复用、几乎不冒“新造词”——既省钱又省心。
