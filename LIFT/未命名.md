下面把 **“从 15 k 条通话摘要 → 多层级意图分类体系”** 的全过程，用“纯原理＋思路”拆成 **8 步**。没有任何代码；你只需理解每一步的**目标、输入输出、关键算法选择**和**为什么这么做**。理解了这些，你就能在任何技术栈里重建同等流程。

---

## 0　总览：一条主线、三个转折点

```
摘要 (15 k) ─▶ ❶ 批次切分 ─▶ ❷ 行级标签 ─▶ ❸ 标签同义折叠
                                         │
                                         ▼
                               ❹ Canonical 叶标签 (≈60-100)
                                         │
                                         ▼
                       ❺ 语义聚合 (层次聚类) ─▶ ❻ 父节点命名
                                         │
                                         ▼
                        ❼ 多层级 Taxonomy  ─▶ ❽ 持续增量治理
```

* **转折点 1**：让 LLM 只负责“逐条打标签”，不承担聚簇；彻底根治漏 ID、结构混乱。
* **转折点 2**：把同义词折叠留给可编程逻辑，成本低且可审计。
* **转折点 3**：层次聚类＋命名，把平铺的叶标签自动抽象成 2–3 层树。

---

## 1　批次切分（❶）

### 目标

* 控制单次 LLM 上下文在 < 4 k tokens，输出稳定。
* 支持并行调用，利用多核、多线程、甚至多 API-key。

### 方法

* **散列**：`batch_id = summary_id mod 2^x`。
* `x` 取 7 或 8（128 或 256 批） → 每批 ≈ 60–120 条摘要。

### 关键心法

散列比随机分组好，因为它**幂等**：同一摘要永远落在同一批，方便重跑和调试。

---

## 2　行级标签（❷）

### 目标

* 给每条摘要打出 1–N 个“叶意图词”。
* 行数恒等 → 不漏 ID，后处理可全依赖代码。

### 方法

1. **提示语**：

   * 简单、强格式：“只输出 JSON 数组，每行 {id, label}”。
   * 允许多标签；同一行用分号或逗号分隔即可。
2. **确定性**：

   * `temperature=0`；
   * 同一输入永远得到同一输出 → 便于缓存与比对。
3. **质量保障**：

   * 调用完马上做**行数校验**：输入 117 行 → 输出也必须 117 行。
   * 解析失败或行数不对 → 重试 1–2 次 → 标记失败批另行复核。

### 为什么这样做

* 把 LLM 的“工作记忆”缩到**一句话**，消除长文本健忘。
* 本阶段只产生\*\*“词料”\*\*，不关心同义、层次，后面再收敛。

---

## [[3　同义折叠 → Canonical 叶标签（❸❹）]]

### 目标

* 把五花八门的行级标签，压缩成 **60–100 个**语义唯一的 canonical 叶标签。
* 保留映射表：`raw_tag → canonical_tag`，可追溯。

### 三层折叠策略

| 层            | 技术                                           | 要解决的“噪声”         | 成本              |
| ------------ | -------------------------------------------- | ---------------- | --------------- |
| **L0** 字面规范化 | NFKC 标准化、大小写、去空格/标点                          | “退款 ” vs “退款”    | O(n) 字符处理       |
| **L1** 模糊匹配  | token\_set\_ratio / Jaro-Winkler ≥ 90        | “退款申请” vs “申请退款” | 毫秒级 CPU         |
| **L2** 语义聚合  | 小型 embedding + 余弦相似 ≥ 0.85，必要时 LLM YES/NO 复核 | “退钱” vs “退费”     | 只跑标签文本，< 1 cent |

> **顺序**重要：先用廉价规则扫“低垂果实”，再用 embedding 处理真同义。

### 输出

* `canon_id`（如 C-042）
* `canon_name`（“退款进度”）
* 别名列表（raw 写法全集）

### 思考要点

* 叶标签才是后续模型和报表的“基本粒子”，必须语义纯净；
* 折叠逻辑可复跑、阈值可调，不影响已归档的 `summary_id → canon_id` 关系。

---

## 4　语义聚合到父层级（❺）

### 目标

* 自动把 60–100 叶标签，聚成 15–25 个二级（Sub-Intent），再聚成 5–10 个一级（Domain）。

### 算法流程

1. **取叶标签文本 → 语义向量**（同一款 embedding 模型即可）。
2. **层次聚类**（hierarchical clustering）：

   * 生成 dendrogram；
   * 定两个截断阈值 `t1 < t0`。
3. **阈值调法**：

   * 观察树状图的“膝点” (elbow)；
   * 或看轮廓系数(Silhouette)最大处。
4. **输出 parent-child 映射**：每叶标签分配 `(domain_id, sub_id)`。

### 原理优势

* 层次聚类天生带“多尺度”树，不像 K-means 只能给一层。
* 阈值可复现；想多/少几个父簇，只需改两个数字。

---

## 5　父节点命名（❻）

### 目标

* 给每个父簇取一个 **≤ 6 字、业务可读** 的名称。
* 名称稳定：相同簇多次重跑应保持一致。

### 方法

**半自动**两步：

1. **自动建议**

   * 对父簇里 Top-N 高频叶名字 + 典型样例，给 LLM：
     “请概括这些意图，用 ≤ 6 字中文或中英短语”。
   * `temperature=0` 保持一致性。
2. **运营校正**

   * 人在简单 UI 上改错别字、合并雷同；
   * 校正动作写入“alias 表”，下次自动套用。

### 关键点

* LLM 负责创造力；人负责合规、品牌口吻。
* alias 表形成**字典**，未来命名全自动化。

---

## 6　多层级 Taxonomy 数据结构（❼）

### 目标

* 构建 **机器可读** 又 **业务友好** 的树。
* 支持版本控制、灰度发布、历史报告可追溯。

### 建议字段

| 层级               | 必要字段                                                   | 说明       |
| ---------------- | ------------------------------------------------------ | -------- |
| Domain           | `domain_id`, `domain_name`                             | 5–10 个   |
| Sub-Intent       | `sub_id`, `sub_name`, `parent_domain_id`               | 15–25 个  |
| Leaf (Canonical) | `canon_id`, `canon_name`, `parent_sub_id`, `aliases[]` | 60–100 个 |

存储可用 **纯 JSON**（如 `taxonomy_2025-06-30-v1.json`）。下游载入后即可通过 `canon_id` 追溯到任何父节点。

---

## 7　持续增量与治理（❽）

### 新摘要进入

1. **行级标签**：照旧调用 LLM。
2. **折叠**：

   * L0/L1：即刻归并；
   * L2：如果新叶与旧叶相似度 < 阈值，则临时放入 `_NEW` 叶池，等待周会专家确认。

### 监控指标

| 指标                          | 异常含义      | 触发动作        |
| --------------------------- | --------- | ----------- |
| 新 leaf 数 / 周 > 叶总数 10 %     | 业务剧变或模型漂移 | 运营检视 `_NEW` |
| 某 canon 内 embedding 方差 > 阈值 | 误合并       | 拆分 canon    |
| 父簇样本分布极不均匀                  | 阈值需调整     | 重跑层次聚类      |

### 版本管理

* 每次调阈值或大规模合并，都产出新 `taxonomy_version`。
* BI 报表、RAG 检索带着 version 字段，历史可复现。

---

## 8　为什么整个流程只用 Python + LangGraph + 文件系统？

| 需求        | 为什么不用数据库                         | 替代                                       |
| --------- | -------------------------------- | ---------------------------------------- |
| **持久化**   | 仅几万行 JSON，文件即可；版本化用时间戳文件名        | `leaf_clusters.json`, `taxonomy_v*.json` |
| **调度/重试** | LangGraph 的节点：自动重跑失败、串并行可控       | 每批形成一个小图                                 |
| **并行**    | ThreadPool / asyncio 足够撑满 API 带宽 | 128 批并发 < 5 min                          |
| **审计**    | 文件天然可 diff；比 SQL 更直观             | Git / DVC                                |

如果未来要 **千万级摘要** 或 **实时写入**，可以再迁移到向量库 + 数据库；但在 15 k 量级完全没必要增加复杂度。

---

### 小结：为什么这条路稳、快、可控？

1. **LLM 只做它擅长的“语义理解”**，所有不确定环节（聚簇、层次、命名稳定性）拆给规则或人工一锤定音。
2. **漏 ID = 0**，因为行数恒等检测；数据质量可自动化验证。
3. **成本线性可估**：行级标签是唯一付费大头；其他步骤是本地矩阵运算。
4. **每个阈值、字典、alias 都显式可调**，出现业务变化时只需改数字或 JSON，不必重写程序。
5. **无数据库、无黑盒**：所有产物都是 plain JSON，Git 即是数据库；迁移、回滚、审计极简。

理解了以上 8 步及其背后原理，你就掌握了 **“LLM + 编程式折叠 + 层次抽象”** 的完整思维框架，可以在任何规模的数据上快速复制并演进。祝你落地顺利！
