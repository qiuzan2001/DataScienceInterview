### 2.1 Definition & Purpose

A **transformation** is any mathematical operation applied to a predictor (or response) variable before modeling.  Its goals are to:

1. **Improve linearity** between $X$ and $Y$, so that linear models (or additive models) fit better.
2. **Stabilize variance** (homoscedasticity) of residuals.
3. **Normalize** heavy-tailed or skewed distributions, making inference (e.g. confidence intervals, hypothesis tests) more reliable.
4. **Control outlier influence** by capping extreme values.
5. **Encode** categorical variables into numeric form for algorithms that require numeric inputs.

---

### 2.2 When & How to Identify the Need for a Transformation

1. **Residual Diagnostics**

   * **Residual vs. fitted plot** shows curvature ⇒ consider non-linear terms.
   * **Residual vs. predictor plot** shows funnel shape ⇒ variance instability, try variance-stabilizing transform.
2. **Distributional Checks**

   * **Histogram / density** of a feature is markedly skewed.
   * **Skewness / kurtosis** statistics far from zero.
   * **Q–Q plot** of residuals or raw $X$ departs from straight line.
3. **Model Performance**

   * Low $R^2$ or high test error despite complex model ⇒ perhaps relationship is non-linear or heteroscedastic.

> **Rule of thumb**: always explore univariate distributions and residual plots before and after fitting your baseline model.

---

### 2.3 Core Transformation Techniques

| Target-Unaware                                    | Target-Aware                     |
| :------------------------------------------------ | :------------------------------- |
| **Dummy coding**                                  | **WOE coding**                   |
| **Binning** (unsupervised: equal-width, quantile) | **Binning** (supervised/optimal) |
| **Winsorisation (Cap/Floor)**                     | **GAM smoothing**                |
| **Box–Cox transform**                             |                                  |
| **Polynomial terms**                              |                                  |
| **Splines** (basis generation only)               |                                  |

* **Target-Unaware** methods look only at the distribution of $X$. You can apply them without ever touching $Y$.
* **Target-Aware** methods leverage information about $Y$ (e.g. class proportions or residuals) when creating the new feature.

| Aspect                                      | **Target-Unaware**                                                               | **Target-Aware**                                                                                                              |
| ------------------------------------------- | -------------------------------------------------------------------------------- | ----------------------------------------------------------------------------------------------------------------------------- |
| **Still any leakage?**                      | No – because $Y$ was never consulted.                                            | When fitted strictly on the training fold and frozen, direct leakage is gone.                                                 |
| **Overfitting risk**                        | Low by construction; transform can’t chase noise in $Y$.                         | **Remains.** The transform can still capture idiosyncrasies of the training labels (e.g., rare-category WOE ≈ ±∞).            |
| **Robustness to covariate shift**           | Higher. Mapping depends only on $X$’s marginal distribution, which moves slowly. | Lower. If the relationship between $X$ and $Y$ drifts, the transform may become misleading.                                   |
| **Handling unseen or rare categories/bins** | Straightforward defaults (e.g., “other” level, continue Box-Cox).                | Must supply fallback rules: WOE for unseen level?  • Pool into “rare” bucket with a global WOE value.                         |
| **Pipeline complexity**                     | Simple: one global fit per variable.  No need to revisit for each CV fold.       | Heavier: during k-fold CV you must refit the transform *within each fold* to keep leakage out of the fold’s validation block. |
| **Interpretability**                        | Typically intuitive (log, polynomial), independent of outcome.                   | Can be very interpretable for risk work (WOE’s log-odds), but values change if class balance shifts.                          |
| **Deployment maintenance**                  | Rarely updated unless raw feature distribution drifts.                           | Must re-estimate whenever you re-train or when $Y$ prevalence changes.                                                        |

---

#### Why WOE is still more fragile than supervised binning—even when fitted only on train

| Feature                         | **WOE Encoding**                                                                                       | **Supervised / Optimal Binning**                                                                                                     |
| ------------------------------- | ------------------------------------------------------------------------------------------------------ | ------------------------------------------------------------------------------------------------------------------------------------ |
| **What is learned from train?** | A **numeric value** per level/bin:  $\text{WOE}(c)=\ln\frac{p_{1c}}{p_{0c}}$.                          | A set of **split points**. The feature later becomes a *categorical* “bin index.”                                                    |
| **Variance on small counts**    | Extremely high: with 1 “good” and 0 “bad,” WOE → +∞ after smoothing.                                   | Only cut-points are learned; if a bin happens to have few events later, its index is still benign.                                   |
| **Effect on downstream model**  | Model sees a *continuous* signal tightly tied to training set’s empirical odds → can over-trust noise. | Model just sees “bin = k.” The predictive signal stems from how bins separate $Y$, but numeric representation (0,1,2…) is arbitrary. |
| **Unseen level / value**        | Requires explicit fallback WOE (often global log-odds). If missing, model may crash.                   | Unseen numeric values are simply assigned to the outermost bin edge or an “overflow” bin.                                            |
| **Drift sensitivity**           | If class mix changes, every WOE value is systematically wrong.                                         | Bins may still be reasonable as long as the *order* of risk across intervals is stable.                                              |

**Bottom line**

* Even with a train-only fit, **target-aware** transforms **still need careful cross-validation plumbing, smoothing, and drift monitoring**.
* **WOE** is powerful for monotonic risk problems but the numeric values can explode on sparse categories and grow stale if class ratios move; that is why practitioners talk about its “data-leakage” potential and always pair it with strict fold-wise fitting and regularization.
