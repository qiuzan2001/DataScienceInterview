### ðŸ”¹ **[[6.1 Data Preparation & Validation]]**

* **Train/Validation/Test Splits** â€“ Proper partitioning for unbiased performance evaluation.
* **Cross-Validation** â€“ Techniques like k-fold or stratified sampling to improve robustness.
* **Data Leakage** â€“ Identifying and preventing unintentional exposure of test data during model training.  Data leakege inside target/feature

---

### ðŸ”¹ **[[6.2 Model Diagnosis_Bias-Variance Tradeoff]]**

* **Underfitting** (High Bias):
  * High error on both training and validation/test data.
* **Overfitting** (High Variance):
  * Low error on training data, but high error on validation/test data.

---

### ðŸ”¹ **[[6.3 Performance Metrics]]**

#### ðŸŸ¦ *Regression Metrics*:

* **RMSE** (Root Mean Squared Error)
* **MAPE** (Mean Absolute Percentage Error)
* **R-squared (RÂ²)**

#### ðŸŸ© *Classification Metrics*:

* **Accuracy**
* **Precision**
* **Recall**
* **AUC** (Area Under the ROC Curve)

---

### ðŸ”¹ **[[6.4 Diagnostic & Visualization Tools]]**

* **ROC Curve** â€“ For evaluating binary classifiers.
* **Residual Chart** â€“ Analyzes error patterns in regression.
* **Lift/Gain Chart** â€“ Measures effectiveness of classification ranking.
* **Posterior EDA** â€“ Exploratory analysis post-modeling to interpret model output and behavior.

---
