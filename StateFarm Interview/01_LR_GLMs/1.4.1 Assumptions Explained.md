### A1. Linearity

* **Role:**

  $$
    E[Y_i \mid X_i] = \beta_0 + \sum_j \beta_j X_{ij}.
  $$

  The model’s mean relationship is a straight line (or hyperplane) in the predictors.
* **Consequence:**
  Guarantees that in principle the model can capture the true mean of $Y$.
* **Example Intuition:**
  If each extra hour of study truly adds 5 points on average, our model

  $$
    E[\text{Score}\mid\text{Hours}] = \beta_0 + 5\times(\text{Hours})
  $$

  can represent that exactly.  If the true effect curved (e.g.\ diminishing returns), a straight line would mis‐fit.

---

### A2. Zero-mean errors

* **Role:**

  $$
    E[\varepsilon_i \mid X_i] = 0.
  $$

  After accounting for the predictors, the errors have no leftover pattern.
* **Consequence:**
  $\displaystyle E[\widehat{\boldsymbol\beta}]=\boldsymbol\beta$. Ensures OLS is **unbiased**.
* **Example Intuition:**
  Among all students who studied 4 hours, some score a bit above the line, some below—but their average deviation is zero.  That balance is what lets our slope estimate (e.g.\ “5 points/hour”) hit the true value on average.

---

### A3. Homoscedasticity

* **Role:**

  $$
    \operatorname{Var}(\varepsilon_i\mid X_i)=\sigma^2\quad\forall\,i.
  $$

  All errors scatter equally around the line, no matter the $X$.
* **Consequence:**
  $\displaystyle \operatorname{Var}(\widehat{\boldsymbol\beta})=\sigma^2(\mathbf X'\mathbf X)^{-1}.$
  Standard errors are valid and comparable.
* **Example Intuition:**
  If 1-hour and 10-hour students both show about ±8 points of scatter around the fitted line, our formula for standard errors is right.  But if high-study students cluster tightly and low-study ones wildly vary, those standard errors mislead.

---

### A4. Independence

* **Role:**

  $$
    \operatorname{Cov}(\varepsilon_i,\varepsilon_{i'})=0,\quad i\neq i'.
  $$

  One observation’s error doesn’t “drag” another’s.
* **Consequence:**
  Together with homoscedasticity,
  $\displaystyle \operatorname{Cov}(\widehat\beta_j,\widehat\beta_m)    = \sigma^2\bigl[(\mathbf X'\mathbf X)^{-1}\bigr]_{jm}.$
* **Example Intuition:**
  If two friends cheat off each other, their exam “luck” errors correlate—violating independence.  In a typical classroom, each student’s deviation from the line is their own.

---

### A5. Normality of errors

* **Role:**
  $\displaystyle \varepsilon_i \sim N(0,\sigma^2).$
  Errors follow a bell curve.
* **Consequence:**
  $\widehat{\boldsymbol\beta}$ is exactly Gaussian, granting exact $t$- and $F$-tests for inference.
* **Example Intuition:**
  When you plot all residuals (actual minus predicted scores), you see a symmetric mound.  That justifies using a t-test to ask “Is studying truly significant?” If the residuals were skewed or had fat tails, those p-values might lie.

---

### A6. No perfect multicollinearity

* **Role:**
  No $X$ is an exact linear combo of the others ⇒ $\mathbf X'\mathbf X$ invertible.
* **Consequence:**
  If violated, $(\mathbf X'\mathbf X)^{-1}$ doesn’t exist and OLS can’t find unique coefficients.
* **Example Intuition:**
  Including both “hours studied” and “minutes studied” (minutes = 60×hours) makes them perfectly collinear.  The model can’t tell which to credit for the score increase.

---

### A7. Correct model specification

* **Role:**
  All relevant predictors are included in the proper form (no omitted variables, correct transforms).
* **Consequence:**
  Omitting a relevant $Z$ that correlates with $X$ and $Y$ biases

  $$
    \operatorname{Bias}(\widehat\beta)
    =(\mathbf X'\mathbf X)^{-1}\mathbf X'\mathbf Z\,\gamma.
  $$
* **Example Intuition:**
  If attendance $Z$ truly matters and good attendees also study more, leaving out $Z$ inflates your “points per hour” slope.  You’d credit hours studied for some of attendance’s effect.

---

#### Bottom Line in Our Exam Example

When you check and (reasonably) satisfy all seven assumptions, OLS delivers an **unbiased**, **efficient**, and **exactly inferential** estimate of “points per hour studied.”  If any assumption falters—say errors aren’t constant or you’ve left out attendance—you risk biased slopes or misleading standard errors, and you’d then look to remedies (e.g.\ robust SEs, weighted regression, or a richer model).
