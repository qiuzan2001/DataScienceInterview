## 🔹 2.1 方差（Variance）：衡量一维数据的“信息量”

### 📌 **方差定义（Variance）**

在一维数据中，**方差**衡量的是数据**离均值的平均距离的平方**，用来描述数据的**分散程度（spread）**：

$$
\text{Var}(x) = \frac{1}{m} \sum_{i=1}^m (x_i - \bar{x})^2
$$

其中：

* $x_i$：第 $i$ 个样本
* $\bar{x}$：样本均值
* $m$：样本数量

---

### ✅ **中心化简化（Mean-centering Simplification）**

为了简化计算，我们通常先将数据**中心化（mean-centered）**，即令：

$$
\bar{x} = 0
$$

此时方差公式简化为：

$$
\text{Var}(x) = \frac{1}{m} \sum_{i=1}^m x_i^2
$$

---

### 🎯 应用到降维（投影目标）：

我们希望找一个**一维方向（单位向量）** $\mathbf{u} \in \mathbb{R}^N$，将原始高维数据 $\mathbf{x}_i \in \mathbb{R}^N$ 投影到 $\mathbf{u}$ 上：

$$
z_i = \mathbf{u}^\top \mathbf{x}_i
$$

我们希望这些投影值 $z_i$ 的方差最大：

$$
\text{maximize } \frac{1}{m} \sum_{i=1}^m (\mathbf{u}^\top \mathbf{x}_i)^2
= \mathbf{u}^\top \left( \frac{1}{m} \sum_{i=1}^m \mathbf{x}_i \mathbf{x}_i^\top \right) \mathbf{u}
= \mathbf{u}^\top S \mathbf{u}
$$

其中 $S$ 是**协方差矩阵（covariance matrix）**。

---

## 🔹 2.2 协方差（Covariance）：衡量两个变量的相关性

### 📌 **协方差定义（Covariance）**

对于两个变量 $x$ 和 $y$，协方差定义为：

$$
\text{Cov}(x, y) = \frac{1}{m} \sum_{i=1}^m (x_i - \bar{x})(y_i - \bar{y})
$$

### ✅ **中心化简化后**：

如果已中心化（$\bar{x} = \bar{y} = 0$），则简化为：

$$
\text{Cov}(x, y) = \frac{1}{m} \sum_{i=1}^m x_i y_i
$$

---

### 🎯 多维数据的协方差矩阵

对于 $N$ 维向量数据 $\mathbf{x}_1, \dots, \mathbf{x}_m \in \mathbb{R}^N$，协方差矩阵定义为：

$$
S = \frac{1}{m} \sum_{i=1}^m \mathbf{x}_i \mathbf{x}_i^\top
\in \mathbb{R}^{N \times N}
$$

其中：

* $S_{ij}$ 表示第 $i$ 个变量和第 $j$ 个变量的协方差
* 对角线是方差，非对角线是协方差

---

## 🎯 目标更新：选择一组正交方向，**最大化方差、最小化冗余**

> 我们现在的目标是：
> **从 N 维空间中选出 K 个方向，使得：**
>
> 1. 投影后的各个维度之间**协方差为 0（线性不相关）**
> 2. 每个方向上的投影方差尽可能大（保留最多信息）

---

### ✅ 最终形式化目标：

令 $U = [\mathbf{u}_1, \dots, \mathbf{u}_K] \in \mathbb{R}^{N \times K}$，每列为一个投影方向（单位向量），我们希望：

$$
\max_{U^\top U = I} \text{tr}(U^\top S U)
$$

* 最大化**投影后数据的总方差**
* 约束 $U$ 是正交矩阵（列向量两两正交、单位长度）
* 解为 $S$ 的**前 K 个特征向量对应的方向**

---

## ✅ 结论（总结为一句话）：

> 降维 = 选择一组正交方向，使得每个方向上的**信息量（方差）最大**，且**彼此不重复（协方差为 0）**

---

## 📘 术语中英对照

| 中文术语  | 英文术语                 |
| ----- | -------------------- |
| 方差    | Variance             |
| 协方差   | Covariance           |
| 协方差矩阵 | Covariance Matrix    |
| 均值中心化 | Mean-centering       |
| 投影    | Projection           |
| 正交向量  | Orthogonal Vectors   |
| 特征向量  | Eigenvectors         |
| 特征值   | Eigenvalues          |
| 最大可分性 | Maximum Separability |

---

如果你需要，我可以：

* 用图形展示：方差最大方向 vs 协方差为 0 的正交方向
* 推导如何从协方差矩阵中得到特征向量（PCA 算法流程）

是否需要继续？
